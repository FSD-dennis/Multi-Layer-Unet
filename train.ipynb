{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:32.350365600Z",
     "start_time": "2024-02-19T02:54:32.311404400Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.099708100Z",
     "start_time": "2024-02-19T02:54:32.352473900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['desktop.ini', 'label', 'test', 'train', 'WQ643945_satellite.tif']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pacKage\n",
    "import loaddata\n",
    "import uNet\n",
    "from pacKage import *\n",
    "from uNet import *\n",
    "from loaddata import *\n",
    "rootPath = os.getcwd()\n",
    "dataPath = os.path.join(rootPath,\"data\")\n",
    "modelPath = os.path.join(rootPath,\"model\")\n",
    "if not os.path.exists(dataPath):\n",
    "    os.makedirs(dataPath)\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "os.listdir(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.198579800Z",
     "start_time": "2024-02-19T02:54:35.100709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "modules_to_reload = [\"pacKage\", \"uNet\", \"loaddata\"]\n",
    "\n",
    "    \n",
    "for module_name in modules_to_reload:\n",
    "    # Dynamically import the module by name\n",
    "    module = __import__(module_name)\n",
    "    # Now reload the module\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.199666Z",
     "start_time": "2024-02-19T02:54:35.116605300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minmax', 'TrainDataset', 'TestDataset', 'train_batch', 'accuracy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaddata.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.199666Z",
     "start_time": "2024-02-19T02:54:35.179464800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataPath, \"train\")\n",
    "label_dir = os.path.join(dataPath, \"label\")\n",
    "test_dir  = os.path.join(dataPath, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transfer our image data into two types of tensor and the label into another tensor**\n",
    "1. (350, 350, 4) for infrared, near infrared, cloud mask, elevation. we call that \"ince\"\n",
    "2. (350, 350, 3) for RGB, we call that \"rgb\"\n",
    "3. (350, 350, 1) for label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create DataLoader for each type of dataset**\n",
    "\n",
    "**I need to consider the \"ince\" and the \"rgb\" data**\n",
    "\n",
    "| Dataloader Type    | Dataloader Name |\n",
    "|-------------------|-----------------|\n",
    "| Train Dataloader  | 1. train_ince_dl |\n",
    "|                   | 2. train_rgb_dl  |\n",
    "| Val Dataloader    | 3. val_ince_dl   |\n",
    "|                   | 4. val_rgb_dl    |\n",
    "| Test Dataloader   | 5. test_ince_dl  |\n",
    "|                   | 6. test_rgb_dl   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.200718600Z",
     "start_time": "2024-02-19T02:54:35.179464800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ince_dl_temp       =     TrainDataset(train_dir = train_dir, label_dir = label_dir, type = \"train\", val_size = 0.2, sep = \"ince\")\n",
    "train_rgb_dl_temp        =     TrainDataset(train_dir = train_dir, label_dir = label_dir, type = \"train\", val_size = 0.2, sep = \"rgb\")\n",
    "val_ince_dl_temp         =     TrainDataset(train_dir = train_dir, label_dir = label_dir, type = \"val\", val_size = 0.2, sep = \"ince\")\n",
    "val_rgb_dl_temp          =     TrainDataset(train_dir = train_dir, label_dir = label_dir, type = \"val\", val_size = 0.2, sep = \"rgb\")\n",
    "test_ince_rgb_dl_temp    =     TestDataset(test_dir = test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T02:54:35.200718600Z",
     "start_time": "2024-02-19T02:54:35.179464800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ince_dl       =     DataLoader(train_ince_dl_temp, batch_size = 8)\n",
    "train_rgb_dl        =     DataLoader(train_rgb_dl_temp, batch_size = 8)\n",
    "val_ince_dl         =     DataLoader(val_ince_dl_temp, batch_size = 8)\n",
    "val_rgb_dl          =     DataLoader(val_rgb_dl_temp, batch_size = 8)\n",
    "test_ince_rgb_dl    =     DataLoader(test_ince_rgb_dl_temp, batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create Unet and training function**\n",
    "\n",
    "*allow me to make an estimation first and inspection usnig torchsummary first*\n",
    "\n",
    "- initiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "incemodel = UShapeNet(4).to(device=device)\n",
    "# summary(incemodel, (4,350,350));\n",
    "rgbmodel = UShapeNet(3).to(device=device)\n",
    "# summary(rgbmodel, (3,350,350));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define the training process!  together with our DataLoader**\n",
    "- training ince model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.99s/it] ?it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62it/s]:49, 12.37s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.57it/s]:24,  8.26s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.52it/s]:14,  7.04s/it]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.53it/s]:06,  6.56s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.88it/s]\n",
      "out of epochs: 100%|██████████| 5/5 [00:34<00:00,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracies is [0.4579092, 0.992591, 0.992591, 0.992591, 0.992591]\n",
      "train_losses is [0.6472536444664001, 1.6129690766334535, 0.2996929168701172, 0.28164169788360593, 0.2778940796852112]\n",
      "val_accuracies is [0.3937413, 0.99517804, 0.99517804, 0.99517804, 0.99517804]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = CombinedLoss(weight_dice=0.5, weight_ce=0.5)\n",
    "optimizer = torch.optim.Adam(incemodel.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in trange(num_epochs, desc=\"out of epochs\", leave=True):\n",
    "    train_epoch_accuracy_list = []\n",
    "    train_epoch_batch_loss = []\n",
    "    val_epoch_accuracy_list = []\n",
    "    for index, batch in enumerate(tqdm(iter(train_ince_dl))):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, incemodel, loss_fn, optimizer)\n",
    "        train_epoch_batch_loss.append(batch_loss)\n",
    "        \n",
    "    for index, batch in enumerate(tqdm(iter(train_ince_dl))):\n",
    "        x, y = batch\n",
    "        temp = accuracy(x, y, incemodel)\n",
    "        train_epoch_accuracy_list.append(temp)\n",
    "    \n",
    "    for index, batch in enumerate(tqdm(iter(val_ince_dl))):\n",
    "        x, y = batch\n",
    "        temp = accuracy(x, y, incemodel)\n",
    "        val_epoch_accuracy_list.append(temp)\n",
    "        \n",
    "    train_accuracies.append(np.mean(train_epoch_accuracy_list))\n",
    "    train_losses.append(np.mean(train_epoch_batch_loss))\n",
    "    val_accuracies.append(np.mean(val_epoch_accuracy_list))\n",
    "    \n",
    "print(f\"train_accuracies is {train_accuracies}\")\n",
    "print(f\"train_losses is {train_losses}\")\n",
    "print(f\"val_accuracies is {val_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save the ince model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(incemodel.state_dict(), os.path.join(modelPath,'ince_model_params.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train rgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.49it/s] ?it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.21it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.58it/s]:23,  5.78s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.41it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.58it/s]:16,  5.63s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62it/s]:11,  5.55s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.53it/s]:05,  5.48s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.57it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n",
      "out of epochs: 100%|██████████| 5/5 [00:27<00:00,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracies is [0.59146464, 0.992591, 0.992591, 0.992591, 0.992591]\n",
      "train_losses is [0.525196635723114, 1.7771829605102538, 0.28945243954658506, 0.28411559462547303, 0.2776166796684265]\n",
      "val_accuracies is [0.54165256, 0.99517804, 0.99517804, 0.99517804, 0.99517804]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = CombinedLoss(weight_dice=0.5, weight_ce=0.5)\n",
    "optimizer = torch.optim.Adam(rgbmodel.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in trange(num_epochs, desc=\"out of epochs\", leave=True):\n",
    "    train_epoch_accuracy_list = []\n",
    "    train_epoch_batch_loss = []\n",
    "    val_epoch_accuracy_list = []\n",
    "    for index, batch in enumerate(tqdm(iter(train_rgb_dl))):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, rgbmodel, loss_fn, optimizer)\n",
    "        train_epoch_batch_loss.append(batch_loss)\n",
    "        \n",
    "    for index, batch in enumerate(tqdm(iter(train_rgb_dl))):\n",
    "        x, y = batch\n",
    "        temp = accuracy(x, y, rgbmodel)\n",
    "        train_epoch_accuracy_list.append(temp)\n",
    "    \n",
    "    for index, batch in enumerate(tqdm(iter(val_rgb_dl))):\n",
    "        x, y = batch\n",
    "        temp = accuracy(x, y, rgbmodel)\n",
    "        val_epoch_accuracy_list.append(temp)\n",
    "        \n",
    "    train_accuracies.append(np.mean(train_epoch_accuracy_list))\n",
    "    train_losses.append(np.mean(train_epoch_batch_loss))\n",
    "    val_accuracies.append(np.mean(val_epoch_accuracy_list))\n",
    "    \n",
    "print(f\"train_accuracies is {train_accuracies}\")\n",
    "print(f\"train_losses is {train_losses}\")\n",
    "print(f\"val_accuracies is {val_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save the rgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rgbmodel.state_dict(), os.path.join(modelPath,'rgb_model_params.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**vaccuracy and loss**\n",
    "- it is super good after one epic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.59146464, 0.992591, 0.992591, 0.992591, 0.992591]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54165256, 0.99517804, 0.99517804, 0.99517804, 0.99517804]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model combined the rgb and ince together!\n",
    "\n",
    "    how to combine the (350, 350, 2) and (350, 350, 2) together??\n",
    "\n",
    "    It is in the [test.ipynb](https://github.com/y1u2a3n4g5/Multi-Layer-Unet/blob/main/test.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visulization of the Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# rgbmodel.eval()\n",
    "# for i in rgbmodel.parameters():\n",
    "#     i.requires_grad = True\n",
    "# dummy_input = torch.randn(8, 3, 350, 350).to(device=device)\n",
    "# y = rgbmodel(dummy_input)\n",
    "# graph = make_dot(y, params=dict(rgbmodel.named_parameters()))\n",
    "# graph.render('rgbmodel', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'incemodel.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "incemodel.eval()\n",
    "for i in incemodel.parameters():\n",
    "    i.requires_grad = True\n",
    "dummy_input = torch.randn(8, 4, 350, 350).to(device=device)\n",
    "y = incemodel(dummy_input)\n",
    "graph = make_dot(y, params=dict(incemodel.named_parameters()))\n",
    "graph.render('incemodel', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
